{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "interracial-prefix",
   "metadata": {},
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "atomic-miracle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['submission_sample.csv', 'test.csv', 'Dataset Description.txt', 'train.csv']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Read data\n",
    "print(os.listdir(\"./data\"))\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "guilty-glenn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning \"A value is trying to be set on a copy of a slice from a DataFrame.\n",
    "# Try using .loc[row_indexer,col_indexer] = value instead\" removing:\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option(\"display.max_rows\", 50, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepting-pulse",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "reduced-attachment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature types\n",
    "Features=train.dtypes.reset_index()\n",
    "Categorical=Features.loc[Features[0]=='object','index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "talented-emphasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical to the begining\n",
    "cols = train.columns.tolist()\n",
    "pos=0\n",
    "for col in Categorical:\n",
    "\tcols.insert(pos, cols.pop(cols.index(col)))\n",
    "\tpos+=1\n",
    "train = train[cols]\n",
    "cols.remove('TARGET')\n",
    "test = test[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "attempted-endorsement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################## TRAIN ##################\n",
      "X21 75\n",
      "X1 3\n",
      "X2 3\n",
      "X3 3\n",
      "X4 16\n",
      "X5 8\n",
      "X6 3\n",
      "X7 3\n",
      "X8 13\n",
      "X9 1\n",
      "X10 3\n",
      "X11 3\n",
      "X12 16\n",
      "X14 3\n",
      "X15 6\n",
      "X16 13\n",
      "X17 13\n",
      "X18 3\n",
      "X22 3\n",
      "X24 95\n",
      "X25 3\n",
      "X26 13\n",
      "X27 281\n",
      "X28 80\n",
      "X29 3\n",
      "X32 29\n",
      "X33 16\n",
      "X34 13\n",
      "X35 3\n",
      "X36 3\n",
      "X37 1794\n",
      "X38 3\n",
      "X40 16\n",
      "X41 58\n",
      "X45 188\n",
      "X46 16\n",
      "X47 24\n",
      "X48 3\n",
      "X50 13\n",
      "X51 3\n",
      "X52 25\n",
      "X53 80\n",
      "X54 80\n",
      "X57 3\n",
      "X59 3\n",
      "X60 188\n",
      "X61 10\n",
      "X63 16\n",
      "X64 80\n",
      "\n",
      "################## TEST ##################\n",
      "X21 28\n",
      "X4 5\n",
      "X5 3\n",
      "X8 5\n",
      "X12 5\n",
      "X16 5\n",
      "X17 5\n",
      "X24 40\n",
      "X26 5\n",
      "X27 110\n",
      "X28 27\n",
      "X32 17\n",
      "X33 5\n",
      "X34 5\n",
      "X37 754\n",
      "X40 5\n",
      "X41 26\n",
      "X45 80\n",
      "X46 5\n",
      "X47 11\n",
      "X50 5\n",
      "X52 11\n",
      "X53 27\n",
      "X54 27\n",
      "X60 80\n",
      "X61 5\n",
      "X63 5\n",
      "X64 27\n"
     ]
    }
   ],
   "source": [
    "# 1) Missings\n",
    "################################################################################\n",
    "# Function to print columns with at least n_miss missings\n",
    "def miss(ds,n_miss):\n",
    "\tmiss_list=list()\n",
    "\tfor col in list(ds):\n",
    "\t\tif ds[col].isna().sum()>=n_miss:\n",
    "\t\t\tprint(col,ds[col].isna().sum())\n",
    "\t\t\tmiss_list.append(col)\n",
    "\treturn miss_list\n",
    "# Which columns have 1 missing at least...\n",
    "print('\\n################## TRAIN ##################')\n",
    "m_tr=miss(train,1)\n",
    "print('\\n################## TEST ##################')\n",
    "m_te=miss(test,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "connected-sending",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missings in categorical features (fix it with an 'NA' string)\n",
    "################################################################################\n",
    "for col in Categorical:\n",
    "\ttrain.loc[train[col].isna(),col]='NA'\n",
    "\ttest.loc[test[col].isna(),col]='NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "subjective-albert",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['ID']!='A1039']\n",
    "train = train[train['ID']!='A2983']\n",
    "train = train[train['ID']!='A3055']\n",
    "train = train[train['ID']!='A4665']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "armed-session",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ranging-metabolism",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Correlations\n",
    "################################################################################\n",
    "# Let's see if certain columns are correlated\n",
    "# or even that are the same with a \"shift\"\n",
    "thresholdCorrelation = 0.99\n",
    "def InspectCorrelated(df):\n",
    "\tcorrMatrix = df.corr().abs() # Correlation Matrix\n",
    "\tupperMatrix = corrMatrix.where(np.triu(np.ones(corrMatrix.shape),k=1).astype(np.bool))\n",
    "\tcorrelColumns=[]\n",
    "\tfor col in upperMatrix.columns:\n",
    "\t\tcorrels=upperMatrix.loc[upperMatrix[col]>thresholdCorrelation,col].keys()\n",
    "\t\tif (len(correls)>=1):\n",
    "\t\t\tcorrelColumns.append(col)\n",
    "\t\t\tprint(\"\\n\",col,'->', end=\" \")\n",
    "\t\t\tfor i in correls:\n",
    "\t\t\t\tprint(i, end=\" \")\n",
    "\tprint('\\nSelected columns to drop:\\n',correlColumns)\n",
    "\treturn(correlColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "selective-tunnel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " X7 -> X1 \n",
      " X11 -> X1 X7 \n",
      " X14 -> X1 X7 X11 \n",
      " X17 -> X8 \n",
      " X18 -> X1 X7 X11 X14 \n",
      " X22 -> X1 X7 X11 X14 X18 \n",
      " X23 -> X19 \n",
      " X25 -> X10 \n",
      " X26 -> X16 \n",
      " X34 -> X16 X26 \n",
      " X35 -> X1 X7 X11 X14 X18 X22 \n",
      " X38 -> X10 X25 \n",
      " X40 -> X4 \n",
      " X46 -> X4 X40 \n",
      " X48 -> X1 X7 X11 X14 X22 X35 \n",
      " X50 -> X4 X46 \n",
      " X52 -> X47 \n",
      " X60 -> X45 \n",
      " X63 -> X33 \n",
      "Selected columns to drop:\n",
      " ['X7', 'X11', 'X14', 'X17', 'X18', 'X22', 'X23', 'X25', 'X26', 'X34', 'X35', 'X38', 'X40', 'X46', 'X48', 'X50', 'X52', 'X60', 'X63']\n"
     ]
    }
   ],
   "source": [
    "# Look at correlations in the original features\n",
    "correlColumns=InspectCorrelated(train.iloc[:,len(Categorical):-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "german-roller",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we are ok, throw them:\n",
    "train=train.drop(correlColumns,axis=1)\n",
    "test=test.drop(correlColumns,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "novel-screen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected columns to drop:\n",
      " []\n"
     ]
    }
   ],
   "source": [
    "# 3) Constants\n",
    "################################################################################\n",
    "# Let's see if there is some constant column:\n",
    "def InspectConstant(df):\n",
    "\tconsColumns=[]\n",
    "\tfor col in list(df):\n",
    "\t\tif len(df[col].unique())<2:\n",
    "\t\t\tprint(df[col].dtypes,'\\t',col,len(df[col].unique()))\n",
    "\t\t\tconsColumns.append(col)\n",
    "\tprint('\\nSelected columns to drop:\\n',consColumns)\n",
    "\treturn(consColumns)\n",
    "\n",
    "consColumns=InspectConstant(train.iloc[:,len(Categorical):-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "alone-spare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we are ok, throw them:\n",
    "train=train.drop(consColumns,axis=1)\n",
    "test=test.drop(consColumns,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dirty-going",
   "metadata": {},
   "source": [
    "# Model - CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "monthly-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=list(train)[1:-1]\n",
    "X_train=train[pred].reset_index(drop=True)\n",
    "Y_train=train['TARGET'].reset_index(drop=True)\n",
    "X_test=test[pred].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "korean-century",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'catboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4c4156b93204>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcatboost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'catboost'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hearing-spank",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'catboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8e37447cc8b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 1) For expensive models (catboost) we first try with validation set (no cv)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcatboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcatboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'catboost'"
     ]
    }
   ],
   "source": [
    "# 1) For expensive models (catboost) we first try with validation set (no cv)\n",
    "################################################################################\n",
    "from catboost import CatBoostClassifier\n",
    "from catboost import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "effective-digest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train / test partition\n",
    "RS=1234 # Seed for partitions (train/test) and model random part\n",
    "TS=0.3 # Validation size\n",
    "esr=10 # Early stopping rounds (when validation does not improve in these rounds, stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "productive-jones",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(X_train, Y_train, test_size=TS, random_state=RS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-credits",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical positions for catboost\n",
    "Pos=list()\n",
    "As_Categorical=Categorical.tolist()\n",
    "As_Categorical.remove('ID')\n",
    "for col in As_Categorical:\n",
    "    Pos.append((X_train.columns.get_loc(col)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-heart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Pool Class (for catboost only)\n",
    "pool_tr=Pool(x_tr, y_tr,cat_features=Pos)\n",
    "pool_val=Pool(x_val, y_val,cat_features=Pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-bracket",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By-hand paramter tuning. A grid-search is expensive\n",
    "# We test different combinations\n",
    "# See parameter options here:\n",
    "# \"https://catboost.ai/en/docs/references/training-parameters/\"\n",
    "model_catboost_val = CatBoostClassifier(\n",
    "          eval_metric='AUC',\n",
    "          iterations=500, # Very high value, to find the optimum\n",
    "          od_type='Iter', # Overfitting detector set to \"iterations\" or number of trees\n",
    "          random_seed=RS, # Random seed for reproducibility\n",
    "          verbose=100) # Shows train/test metric every \"verbose\" trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-structure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Technical\" parameters of the model:\n",
    "params = {'objective': 'Logloss',\n",
    "\t\t  'learning_rate': 0.1, # learning rate, lower -> slower but better prediction\n",
    "\t\t  'depth': 3, # Depth of the trees (values betwwen 5 and 10, higher -> more overfitting)\n",
    "\t\t  'min_data_in_leaf': 10,\n",
    "\t\t  'l2_leaf_reg': 0, # L2 regularization (between 3 and 20, higher -> less overfitting)\n",
    "\t\t  'rsm': 0.95, # % of features to consider in each split (lower -> faster and reduces overfitting)\n",
    "\t\t  'subsample': 0.95, # Sample rate for bagging\n",
    "\t\t  'random_seed': RS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-warrant",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_catboost_val.set_params(**params)\n",
    "\n",
    "print('\\nCatboost Fit (Validation)...\\n')\n",
    "model_catboost_val.fit(X=pool_tr,\n",
    "                       eval_set=pool_val,\n",
    "                       early_stopping_rounds=esr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-arabic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Shap Importance for the features of the final model\n",
    "################################################################################\n",
    "# Shap methodology:\n",
    "# \"https://medium.com/@gabrieltseng/interpreting-complex-models-with-shap-values-1c187db6ec83\"\n",
    "# Catboost has already SHAP integrated\n",
    "# Comes as variation with respect to LOG Odds\n",
    "ShapImportance=model_catboost.get_feature_importance(data=pool_train,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t     type='ShapValues',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t prettified=True,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t verbose=False)\n",
    "ShapValues = ShapImportance.iloc[:, :-1]\n",
    "ShapValues.columns=list(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-charter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Picture in Logodds\n",
    "################################################################################\n",
    "from shap import summary_plot\n",
    "num_features=30\n",
    "summary_plot(ShapValues.values,X_train,max_display=num_features,plot_type='dot')\n",
    "\n",
    "# Variable Importance Recap\n",
    "################################################################################\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "Importance=ShapValues.abs().mean(axis=0)\n",
    "Importance=pd.DataFrame({'Feature':Importance.index.tolist(),'Importance':Importance}).sort_values(by=['Importance'],ascending=False).reset_index(drop=True)\n",
    "# Top features:\n",
    "plt.figure(figsize=(15, 15))\n",
    "sns.barplot(x=\"Importance\",\n",
    "\t\t\ty=\"Feature\",\n",
    "\t\t\tdata=Importance[:num_features],\n",
    "\t\t\tpalette=sns.color_palette(\"Blues_d\",\n",
    "\t\t\tn_colors=Importance[:num_features].shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "royal-blowing",
   "metadata": {},
   "source": [
    "## Predictions - Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-vanilla",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction (All train model)\n",
    "test['Pred']=model_catboost.predict_proba(X_test)[:,1]\n",
    "catboost_submission=pd.DataFrame(test[['ID','Pred']])\n",
    "\n",
    "# Cv predictions\n",
    "catboost_cv_train=train[['ID']]\n",
    "catboost_cv_train['catboost_pred']=Catboost_train['train_yhat']\n",
    "catboost_cv_test=test[['ID']]\n",
    "catboost_cv_test['catboost_pred']=Catboost_test['test_yhat']\n",
    "\n",
    "# Outputs to .csv\n",
    "catboost_submission.to_csv(\"BBDD Output/catboost_submission.csv\", index = False)\n",
    "catboost_cv_train.to_csv(\"BBDD Output/catboost_cv_train.csv\", index = False)\n",
    "catboost_cv_test.to_csv(\"BBDD Output/catboost_cv_test.csv\", index = False)\n",
    "Importance.to_csv(\"BBDD Output/catboost_importance.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
